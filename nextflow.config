//============================================================================//
// Define params
//============================================================================//

// Global input
//============================================================================//
params.in_files = "input/*fasta"
params.out_dir = 'output'
params.entry_point = "mmseqs" // options: 'mmseqs' or 'colabfold'

// colabfold workflow inputs
//============================================================================//
// mmseqs
params.reference_fasta = ""

// colabfold
params.COLABFOLD_num_recycles = 3
params.COLABFOLD_stop_at_score = 70
params.COLABFOLD_stop_at_score_below = 40
params.COLABFOLD_num_models = 3
params.COLABFOLD_custom_templates_dir = ""


//============================================================================//
// Process
//============================================================================//
profiles {

  sge {
      process {

            // Global setting
            executor = 'sge'
            penv = 'smp'
            clusterOptions = { '-V -S /bin/bash' }
            cache = 'lenient'
            //conda = "$baseDir/resources/conda/conda_linux.yml"

            // Error handling
            errorStrategy = 'retry'
            maxRetries = 2

            // resources
            withName: mmseqs2 {
              beforeScript = "module load Sali gcc/10.2.1 || true"
              time = { 1.h * task.attempt }
              memory = { 30.GB * task.attempt }
              cpus = { 5 * task.attempt }
              // queue = { task.time < 30.m ? "short.q" : "long.q" } - not needed in wynton
            }

            withName: colabfold {
              beforeScript = "module load Sali gcc/10.2.1 cuda/11.5.0  || true ; export CUDA_VISIBLE_DEVICES=\$SGE_GPU"
              time = { 119.m * task.attempt }
              memory = { 20.GB + 10.GB * task.attempt }
              cpus = 1
              queue = "gpu.q"
            }
      }

      

      //============================================================================//
      // Misc settings
      //============================================================================//

      executor {
            // Let nextflow submit up to this many jobs in parallel at one time
            queueSize = 150
      }

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

      conda {
            cacheDir = "/wynton/group/gladstone/users/jnomburg/software/nf_conda_envs"
      }

  } // this closes the sge profile

  mac {
      process {

            // Global setting

            // Error handling
            errorStrategy = 'retry'
            maxRetries = 2

            // resources
            withName: mmseqs2 {
              time = 1.h
              memory = 10.GB
              cpus = 5
            }
      }


      
      //============================================================================//
      // Misc settings
      //============================================================================//

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

  } // this closes the mac profile

  docker {
      process {

            // Global setting
            docker.enabled = true

            // Error handling
            errorStrategy = 'retry'
            maxRetries = 2

            // resources
            withName: mmseqs2 {
              container = "quay.io/biocontainers/mmseqs2"
              time = 1.h
              memory = 10.GB
              cpus = 5
            }
      }


      
      //============================================================================//
      // Misc settings
      //============================================================================//

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

  } // this closes the docker profile

  hybrid {
      process {            

            withName: mmseqs2 {
              beforeScript = "module load Sali gcc/10.2.1 || true"
              time = { 1.h * task.attempt }
              memory = { 30.GB * task.attempt }
              cpus = { 5 * task.attempt }
              executor = 'sge'
              penv = 'smp'
              clusterOptions = { '-V -S /bin/bash' }
              cache = 'lenient'

              // Error handling
              errorStrategy = {task.attempt <= 3 ? 'retry' : 'ignore'}
              maxRetries = 2
            }

            withName: colabfold {
              time = 10.m
              memory = 15.GB
              cpus = 1
              executor = 'awsbatch'
              queue = 'colabfold_spot'
              container = "230218818/colabfold"
	        process.accelerator = 1
              process.containerOptions = "--gpus all"

              // Error handling
              errorStrategy = "ignore"
            }
      }

      //region where we want to run this in
      aws.region = 'us-east-1'

      // This is the path to the awscli downloaded into the custom AMI
      aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'

      // The custom AMI has the colabfold params copied to /home/ec2-user/params
      // This setting mounts that directory to the docker container
      aws.batch.volumes = "/home/ec2-user/params:/root/.cache/colabfold"

      
      //============================================================================//
      // Misc settings
      //============================================================================//

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

  } // this closes the hybrid profile

  biotite {
      process {           

            withName: mmseqs2 {
              beforeScript = "module load Sali gcc/10.2.1 || true"
              time = { 1.h * task.attempt }
              memory = { 30.GB * task.attempt }
              cpus = { 5 * task.attempt }
              executor = 'slurm'
              cache = 'lenient'

              // Error handling
              errorStrategy = {task.attempt <= 3 ? 'retry' : 'ignore'}
              maxRetries = 2
            }

            withName: colabfold {
              time = 2.h
              executor = 'slurm'
              clusterOptions = { '--gpus 1 --partition gpu' }
	        process.accelerator = 1
              process.containerOptions = "--gpus all"

              // Error handling
              errorStrategy = {task.attempt <= 3 ? 'retry' : 'ignore'}
              maxRetries = 2
            }
      }

      //============================================================================//
      // Misc settings
      //============================================================================//

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

      executor {
            // Let nextflow submit up to this many jobs in parallel at one time
            queueSize = 10
      }

  } // this closes the biotite profile

  lw {
      process {           

            withName: mmseqs2 {
              time = { 1.h * task.attempt }
              memory = { 30.GB * task.attempt }
              cpus = { 5 * task.attempt }
              executor = 'slurm'
              cache = 'lenient'

              // Error handling
              errorStrategy = {task.attempt <= 3 ? 'retry' : 'ignore'}
              maxRetries = 2
            }

            withName: colabfold {
              time = 2.h
              beforeScript = "module load cuda/11.6"
              executor = 'slurm'
              clusterOptions = { '--account=ac_ribosome --partition=es1 --nodes=1 --ntasks=1 --cpus-per-task=2 --gres=gpu:1 --qos=es_normal' }
	        process.accelerator = 1
              process.containerOptions = "--gpus all"

              // Error handling
              errorStrategy = {task.attempt <= 3 ? 'retry' : 'ignore'}
              maxRetries = 2
            }
      }

      //============================================================================//
      // Misc settings
      //============================================================================//

      report {
            enabled = true
            file = "$params.out_dir/nf_information/pipeline_report.html"
      }

      timeline {
            enabled = true
            file = "$params.out_dir/nf_information/timeline.html"
          }

      trace {
            enabled = true
            file = "$params.out_dir/nf_information/trace.tsv"
      }

      executor {
            // Let nextflow submit up to this many jobs in parallel at one time
            queueSize = 100
      }

  } // this closes the lw profile


} // This closes the profiles section
