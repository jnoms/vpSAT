{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnoms/vpSAT/blob/main/bin/colab/QueryStructures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-6ChvDD_ahb"
      },
      "source": [
        "# **Foldseek Viral Structure Alignment**\n",
        "The aim of this notebook is to enable users to use Foldseek to conduct structural searches against the database of predicted viral structures established by Nomburg et al., \"*Birth of new protein folds and functions in the virome*\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyl_DFdODb_T"
      },
      "source": [
        "# **Directions**\n",
        "\n",
        "This notebook is split into individual steps to enable searching of one or more structure (.pdb) files against the viral structure database. If you do not have a structure, we recommend you predict one based using the publically available Colabfold notebook (https://github.com/sokrypton/ColabFold).  \n",
        "\n",
        "## Quick start\n",
        "1. Specify search parameters in section 2. The defaults are sensible, so this is optional.\n",
        "2. In the toolbar above, select Runtime --> Run all\n",
        "3. In section 3, upload a PDB file or a zip file containing multiple PDB files.\n",
        "4. Your results will appear in subsequent cells.\n",
        "\n",
        "\n",
        "## More details:\n",
        "* To run additional searches, simply select Runtime --> Run all again to prompt a new upload in section 3.\n",
        "* In section 5, there are two output tables.\n",
        " * The first table shows information on the protein clusters to which your hits reside - this will tell you, for example, how many hits belong to each protein cluster. You can then investigate all cluster members in section 7 using the cluster_ID.\n",
        " * The second table simply displays all hits, along with their cluster_ID and all associated output fields.\n",
        "* Executing section 6 prompts a download of the foldseek results file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9b9LpqgARpq"
      },
      "source": [
        "##**1. Setup**\n",
        "\n",
        "This step downloads required files and packages, including Foldseek, that are necessary to search across the database for viral structures of interest against the query input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9Z8jW0nKo3X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "from google.colab import files\n",
        "import subprocess\n",
        "import zipfile\n",
        "import os\n",
        "import io\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from ipywidgets import Layout\n",
        "\n",
        "# Check if Foldseek is already downloaded\n",
        "if not os.path.exists('./foldseek-linux-avx2.tar.gz'):\n",
        "\n",
        "    #Silencing main output\n",
        "    import sys\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = io.StringIO()\n",
        "\n",
        "    #Download Foldseek\n",
        "    !wget https://github.com/steineggerlab/foldseek/releases/download/8-ef4e960/foldseek-linux-avx2.tar.gz ; tar xvzf foldseek-linux-avx2.tar.gz\n",
        "\n",
        "    sys.stdout = old_stdout\n",
        "    print(\"\\nFoldseek downloaded successfully\")\n",
        "else:\n",
        "    print(\"\\nFoldseek is already downloaded.\")\n",
        "\n",
        "# Check if the target directory is already downloaded\n",
        "target_directory = '/content/target_extracted_folder/'\n",
        "if not os.path.exists(target_directory):\n",
        "\n",
        "    #Silencing main output\n",
        "    import sys\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = io.StringIO()\n",
        "\n",
        "    !wget https://zenodo.org/records/10685505/files/structure_foldseek_database_2023-11-27.zip?download=1\n",
        "\n",
        "    # Filename of the zip file\n",
        "    target_zip_file = '/content/structure_foldseek_database_2023-11-27.zip?download=1'\n",
        "\n",
        "    # Directory to extract the contents\n",
        "    target_extract_dir = '/content/target_extracted_folder/'\n",
        "\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    os.makedirs(target_extract_dir, exist_ok=True)\n",
        "\n",
        "    # Open the zip file\n",
        "    with zipfile.ZipFile(target_zip_file, 'r') as zip_ref:\n",
        "        # Extract all the contents to the extraction directory\n",
        "        zip_ref.extractall(target_extract_dir)\n",
        "\n",
        "    # List the extracted files\n",
        "    target_extracted_files = os.listdir(target_extract_dir)\n",
        "\n",
        "    # Get the target_file_path\n",
        "    target_file_path = target_extract_dir + target_extracted_files[0]+'/db'\n",
        "    sys.stdout = old_stdout\n",
        "\n",
        "    print(\"\\nTarget database downloaded successfully\")\n",
        "else:\n",
        "    print(\"\\nTarget database is already downloaded.\")\n",
        "\n",
        "\n",
        "\n",
        "# Check if the structure file is in the directory. If not, download it\n",
        "file_path = 'media-1.xlsx?download=true.1'\n",
        "\n",
        "if os.path.isfile(file_path):\n",
        "    print('\\nStructures file is already downloaded')\n",
        "else:\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = io.StringIO()\n",
        "    !wget https://www.biorxiv.org/content/biorxiv/early/2024/01/23/2024.01.22.576744/DC1/embed/media-1.xlsx?download=true\n",
        "    sys.stdout = old_stdout\n",
        "    print(\"\\nStructures file downloaded successfully\")\n",
        "\n",
        "#read in the structures file\n",
        "structure_df = pd.read_excel('media-1.xlsx?download=true')\n",
        "\n",
        "print(\"\\nSetup completed\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR64IB0m8lLO"
      },
      "source": [
        "## **2. User Parameters**\n",
        "\n",
        "*Input the desired parameters below:*\n",
        "\n",
        "**Coverage** - Display the matches above this threshold of alignment/residue coverageâ€”higher coverage value results in wider range of alignments (default: 0, meaning no coverage restriction)\n",
        "\n",
        "**Coverage Mode** -\n",
        "> 0 = Coverage of **both** *query and target*\n",
        "\n",
        ">1 = Coverage of **only** *target*\n",
        "\n",
        ">2 = Coverage of **only** *query*\n",
        "\n",
        "**E-value** - Sensitivity value, higher e-value produces more distant structures (Range: 0-infinity)\n",
        "\n",
        "**Output Format** - Indicate the desired output fields. Consult the Foldseek readme for more information: https://github.com/steineggerlab/foldseek?tab=readme-ov-file#output-search\n",
        "\n",
        "(Default: query, target, fident, alnlen, mismatch, gapopen, qstart, qend, tstart, tend, evalue, bits, rmsd, prob, alntmscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_ZnVCSHPEPq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create parameters for user input with default values\n",
        "coverage = 0 #@param {type:\"number\"}\n",
        "coverage_mode = 0 #@param {type:\"integer\"}\n",
        "e = 10 #@param {type:\"number\"}\n",
        "format_output = 'query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,rmsd,prob,alntmscore' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3OECQfW_dGL"
      },
      "source": [
        "### **3. Upload File Below**\n",
        "\n",
        "Upload either a single .pdb file or a zip file of .pdb files below:\n",
        "\n",
        "(Upload file widget will appear after pressing *Run All*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "omDxcN_1vjNF"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "#print(\"Please Upload a single pdb file or a zip file of pdb files\")\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "#check if the file is is a single pdb file or a zip file\n",
        "for file_name, content in uploaded_file.items():\n",
        "  if file_name.endswith('.pdb'):\n",
        "    print(\"\\n This is a pdb file\")\n",
        "    query_file_path = '/content'+'/' +file_name\n",
        "\n",
        "  elif file_name.endswith('.zip'):\n",
        "    print(\"\\n This is a zip file\")\n",
        "\n",
        "    #make query_folder_path\n",
        "    query_folder_path = '/content/query_extracted_folder/'\n",
        "    os.makedirs(query_folder_path, exist_ok=True)\n",
        "\n",
        "    # Extract zip file\n",
        "    with zipfile.ZipFile(io.BytesIO(content), 'r') as zObject:\n",
        "        zObject.extractall(path=query_folder_path)\n",
        "\n",
        "    for item in os.listdir(query_folder_path):\n",
        "    # Construct the full path of the folder containing pdb files\n",
        "      query_file_path = os.path.join(query_folder_path, item)\n",
        "\n",
        "    print(\"\\n Contents in zip file successfully extracted\")\n",
        "  else:\n",
        "    print(\"\\n This is an unknown file. Please upload the correct file format\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AEV8_uVQo7b",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **4. Run Foldseek**\n",
        "output_file_path = \"output.m8\"\n",
        "\n",
        "import sys\n",
        "old_stdout = sys.stdout\n",
        "sys.stdout = io.StringIO()\n",
        "\n",
        "!/content/foldseek/bin/foldseek easy-search \"{query_file_path}\" \"{target_file_path}\" {output_file_path} tmpFolder -c {coverage} --cov-mode {coverage_mode} -e {e} --format-output \"{format_output}\"\n",
        "sys.stdout = old_stdout\n",
        "\n",
        "print(\"\\n Foldseek Run Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQqVVSEcrJLu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **5. Display Alignment Results**\n",
        "\n",
        "#add column names to output data\n",
        "output_df = pd.read_csv(output_file_path, delimiter='\\t', names=format_output.split(','))\n",
        "\n",
        "output_df['target'] = output_df['target'].str[:-4]\n",
        "\n",
        "#merge output_df with structures_df to obtain the cluster_id and cluster_count\n",
        "structure_df = structure_df.copy()\n",
        "structure_df['cluster_ID'] = structure_df['cluster_ID'].astype(str)\n",
        "structure_df['cluster_count'] = structure_df['cluster_count'].astype(str)\n",
        "\n",
        "structure_df = structure_df[['cluster_member','cluster_ID', 'cluster_count']]\n",
        "merged_output_df = pd.merge(output_df, structure_df, left_on='target', right_on='cluster_member', how='left')\n",
        "#if cluster_member, cluster_iD, cluster_count is nan, fill in the values with unassigned\n",
        "merged_output_df['cluster_member'] = merged_output_df['cluster_member'].fillna('unassigned')\n",
        "merged_output_df['cluster_ID'] = merged_output_df['cluster_ID'].fillna('unassigned')\n",
        "merged_output_df['cluster_count'] = merged_output_df['cluster_count'].fillna('unassigned')\n",
        "\n",
        "#select relevant values for the final output table\n",
        "merged_output_df.drop(columns=['cluster_member'], inplace=True)\n",
        "merged_output_df.insert(2, 'cluster_ID', merged_output_df.pop('cluster_ID'))\n",
        "merged_output_df.insert(3, 'cluster_count', merged_output_df.pop('cluster_count'))\n",
        "\n",
        "\n",
        "#Import interactive data table\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# Displaying alignment results\n",
        "cluster_counts_df = merged_output_df.drop_duplicates('target')\n",
        "cluster_counts_df = cluster_counts_df['cluster_ID'].value_counts().rename_axis('cluster_ID').reset_index(name='Number of proteins found')\n",
        "cluster_counts_df['Fraction of total hits'] = round((cluster_counts_df['Number of proteins found']/cluster_counts_df['Number of proteins found'].sum()),2)\n",
        "cluster_counts_df = cluster_counts_df.sort_values(by='Fraction of total hits', ascending= False)\n",
        "cluster_counts_df = pd.merge(cluster_counts_df, structure_df.drop_duplicates('cluster_ID'), on = 'cluster_ID', how='left')\n",
        "\n",
        "cluster_counts_df['Fraction of cluster with an alignment'] = round((cluster_counts_df['Number of proteins found']/cluster_counts_df['cluster_count'].astype(float)),2)\n",
        "cluster_counts_df = cluster_counts_df.copy()\n",
        "cluster_counts_df = cluster_counts_df[['cluster_ID', 'Number of proteins found', 'Fraction of total hits', 'Fraction of cluster with an alignment']]\n",
        "cluster_counts_df['Fraction of cluster with an alignment'] = cluster_counts_df['Fraction of cluster with an alignment'].fillna(\"NA\")\n",
        "\n",
        "print(\"Number of clusters found in alignment results: \", len(cluster_counts_df) )\n",
        "print(\"\\nDisplaying clusters found in alignment results in table below: \\n\")\n",
        "display(data_table.DataTable(cluster_counts_df, include_index=False, num_rows_per_page=15))\n",
        "\n",
        "print(\"\\nDisplaying alignment results in table below: \")\n",
        "display(data_table.DataTable(merged_output_df, include_index=False, num_rows_per_page=15))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **6. Download Alignment Results**\n",
        "merged_output_df.to_csv('final_output.csv', index=False)\n",
        "files.download('final_output.csv')\n",
        "\n",
        "print(\"File Downloaded\")\n"
      ],
      "metadata": {
        "id": "srxfT_1Gg7mW",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28e3505f-b127-4cb8-8f96-d18c724804d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1bd9372-0333-4aa9-a2a4-c7eb4f8c29bd\", \"final_output.csv\", 27915)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **7. Explore Cluster Members**\n",
        "clusterID = '' #@param {type:\"string\"}\n",
        "clusterID_results = merged_output_df[merged_output_df['cluster_ID']==clusterID]\n",
        "display(data_table.DataTable(clusterID_results, include_index=True, num_rows_per_page=15))"
      ],
      "metadata": {
        "id": "Aq54pqbTg7jV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}